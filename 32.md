### 1. 실험(Experiment) 명명법: [프로젝트/도메인]_[예측대상]

실험(Experiment)은 가장 큰 단위이므로, 이름만 보고도 **어떤 비즈니스 문제를 해결하려는지** 명확히 알 수 있어야 합니다.

- **목표**: 이 실험에 관련된 모든 실행(Run)을 쉽게 찾고 그룹화할 수 있어야 합니다.
    
- **형식**: snake_case (소문자와 언더스코어) 사용을 권장합니다.
    
- **구조**: [팀/제품/도메인]_[예측대상/목표]_[선택적_추가정보]
    

|   |   |   |
|---|---|---|
|좋은 예시|나쁜 예시|설명|
|churn_prediction_premium_users|test_project|무엇을 위한 실험인지 명확합니다.|
|recommend_engine_ctr|user_kim_exp1|어떤 제품의 클릭률 예측인지 알 수 있습니다.|
|fraud_detection_creditcard_v2|20250906_test|서비스명과 버전 정보를 통해 구체화합니다.|

**코드 적용:**

codePython

```
mlflow.set_experiment("churn_prediction_premium_users")
```

---

### 2. 실행(Run) 명명법: [모델]_[핵심특징]_[주요파라미터]

실행(Run)은 실험 내에서의 개별 시도입니다. 목록에서 이름만 봐도 **다른 실행과 무엇이 다른지** 구별할 수 있어야 합니다.

- **목표**: UI 목록에서 클릭하지 않고도 실행의 핵심적인 특징을 파악하는 것입니다.
    
- **형식**: snake_case 또는 kebab-case를 사용합니다.
    
- **구조**: [알고리즘/아키텍처]_[데이터/피처정보]_[핵심튜닝파라미터]_[선택적_날짜/ID]
    

|   |   |   |
|---|---|---|
|좋은 예시|나쁜 예시|설명|
|lgbm_base_features_md10|my_first_run|LightGBM, 기본 피처, max_depth=10 임을 암시|
|rf_oversampled_data_tuned|run_20250906|RandomForest, 오버샘플링 데이터, 튜닝된 버전|
|bert_finetuned_all_text|test|BERT 모델, 전체 텍스트로 파인튜닝|

**주의:** 모든 파라미터를 이름에 넣으려 하지 마세요! 그 정보는 mlflow.log_params()가 기록하는 역할입니다. 이름에는 **이번 실행을 특별하게 만드는 가장 핵심적인 차이점 1~2개**만 넣는 것이 좋습니다.

**코드 적용:**

codePython

```
with mlflow.start_run(run_name="lgbm_base_features_md10"):
    # ... your code ...
```

---

### 3. 그 외 중요한 명명법 적용 대상

실험과 실행 외에도 명명 규칙을 적용하면 좋은 곳들이 있습니다. 바로 **태그(Tags)**와 **아티팩트(Artifacts)**, 그리고 **모델 레지스트리(Model Registry)**입니다.

#### **태그 (Tags): 실행에 붙이는 '꼬리표'**

이름에 다 담지 못하는 메타데이터를 구조적으로 관리하는 최고의 방법입니다. 태그는 **검색과 필터링**을 매우 강력하게 만들어 줍니다.

- **목표**: 특정 조건을 가진 실행들을 쉽게 필터링하거나 추가 정보를 제공합니다.
    
- **형식**: key: value 쌍. Key는 snake_case를 권장합니다.
    

**추천 태그 Key:**

- developer: 이 실험을 진행한 사람 ("jane.doe")
    
- data_version: 사용한 데이터셋의 버전 ("v2.4.1")
    
- source_code: 사용한 소스코드의 Git 커밋 해시 ("a1b2c3d")
    
- validation_type: 검증 방법 ("k-fold_5_split")
    
- status: 실행의 상태 ("running", "finished", "failed")
    

**코드 적용:**

codePython

```
mlflow.set_tag("developer", "hong_gildong")
mlflow.set_tag("data_version", "customer_db_2025_q3")
```

#### **아티팩트 (Artifacts): 저장하는 모든 파일**

모델 파일, 피처 중요도 이미지, 혼동 행렬(confusion matrix) 등 저장하는 모든 파일의 이름입니다.

- **목표**: 실행 상세 페이지의 Artifacts 뷰에서 파일의 역할을 명확히 알아볼 수 있게 합니다.
    
- **규칙**: 직관적이고 설명적인 이름을 사용합니다.
    
    - feature_importance.png
        
    - confusion_matrix_test_set.png
        
    - predictions_on_unseen_data.csv
        

**코드 적용:**

codePython

```
plt.savefig("feature_importance.png")
mlflow.log_artifact("feature_importance.png")
```

#### **모델 레지스트리 (Model Registry): '제품화'될 모델의 공식 이름**

수많은 실행 중 "이 모델을 실제 서비스에 사용하자!"라고 결정했을 때, 이 모델을 등록하는 곳이 모델 레지스트리입니다. 이 이름은 **API 엔드포인트나 다른 서비스에서 모델을 호출할 때 사용**되므로 매우 중요합니다.

- **목표**: 서비스 관점에서 모델의 역할을 명확히 정의합니다.
    
- **규칙**: 실험 이름과 유사하게, 비즈니스 역할을 중심으로 명명합니다.
    
    - churn-predictor-premium
        
    - product-recommender-main