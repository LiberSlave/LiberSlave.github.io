![image](/images/Pasted-image-20250920080321.png)

## 규제 
### 1. LightGBM (부스팅 계열)에서의 규제

LightGBM이나 XGBoost 같은 부스팅 모델은 L1, L2 규제를 **매우 적극적으로 사용하며, 이는 모델 성능에 결정적인 영향**을 미칩니다. 여기서 규제는 신경망의 가중치가 아니라 **리프 노드의 출력 값(leaf output scores)에 적용됩니다.**

- **L1 규제 (reg_alpha 또는 lambda_l1):**
    
    - **작동 방식:** 각 리프 노드가 가지는 출력 값의 **절댓값**에 페널티를 부여합니다.
        
    - **효과:** 이 페널티로 인해 일부 리프 노드의 출력 값이 정확히 0이 될 수 있습니다. 이는 특정 분기(split)가 최종 예측에 아무런 기여도 하지 않게 만들어, 실질적으로 트리의 복잡도를 줄이는 효과(가지치기와 유사)를 낳습니다. 모델이 덜 중요한 특징을 무시하게 만듭니다.
        
- **L2 규제 (reg_lambda 또는 lambda_l2):**
    
    - **작동 방식:** 각 리프 노드가 가지는 출력 값의 **제곱**에 페널티를 부여합니다.
        
    - **효과:** 리프 노드의 출력 값이 너무 크거나 극단적으로 튀는 것을 막아줍니다. 모든 출력 값들을 전반적으로 부드럽게(smooth) 만들어 모델을 더 안정적으로 만듭니다. **일반적으로 가장 널리 쓰이고 효과적인 규제 방식입니다.**
        

**결론적으로, LightGBM에서 reg_alpha와 reg_lambda를 사용하는 것은 모델이 훈련 데이터의 노이즈에 과민하게 반응하여 너무 극단적인 예측 값을 만들어내는 것을 방지하고, 더 안정적이고 일반화된 모델을 만드는 데 직접적인 도움을 줍니다.**

---

### 2. 랜덤 포레스트(Random Forest)에서의 규제

랜덤 포레스트는 LightGBM처럼 L1, L2 규제 파라미터를 직접적으로 사용하지 않습니다. 대신, **모델의 구조 자체에 과적합을 방지하는 여러 기법이 내장**되어 있으며, 하이퍼파라미터 튜닝을 통해 이를 제어합니다.

랜덤 포레스트의 주요 과적합 방지 기법:

1. **배깅 (Bagging):** 데이터를 무작위로 복원 추출(bootstrap)하여 여러 개의 다른 데이터셋을 만들고, 각 데이터셋으로 별개의 결정 트리를 학습시킵니다. 개별 트리가 특정 데이터에 과적합되더라도, 최종적으로는 여러 트리의 예측을 평균(또는 투표)내기 때문에 전체 모델의 과적합이 줄어듭니다.
    
2. **특성 무작위성 (Feature Randomness):** 각 트리의 각 분기점을 만들 때, 모든 특성(feature)을 고려하는 것이 아니라 특성의 일부만 무작위로 선택하여 최적의 분기점을 찾습니다. 이는 트리들이 서로 다른 패턴을 학습하게 하여 모델의 다양성을 높이고 일반화 성능을 향상시킵니다.
    
3. **트리 깊이 및 크기 제한 (직접적인 규제):** 사용자가 하이퍼파라미터를 통해 직접 모델의 복잡도를 제어합니다.
    
    - max_depth: 트리의 최대 깊이를 제한.
        
    - min_samples_leaf: 리프 노드가 되기 위해 필요한 최소한의 데이터 수.
        
    - min_samples_split: 노드를 분기하기 위해 필요한 최소 데이터 수.
        

---

### 요약 비교

|             |                   |                                     |                                         |
| ----------- | ----------------- | ----------------------------------- | --------------------------------------- |
| 구분          | 신경망               | LightGBM (부스팅 계열)                   | 랜덤 포레스트 (배깅 계열)                         |
| **규제 대상**   | 연결선의 **가중치(w)**   | 리프 노드의 **출력 값(score)**              | **모델 구조 자체** (앙상블 방식) 및 **트리 크기**       |
| **주요 파라미터** | L1/L2 Regularizer | **reg_alpha (L1), reg_lambda (L2)** | max_depth, min_samples_leaf 등           |
| **핵심 원리**   | 가중치가 커지는 것에 페널티   | 리프 노드 값이 극단적으로 커지는 것에 페널티           | 여러 개의 약한 모델(얕은 트리)을 만들고, 무작위성을 부여하여 앙상블 |
