### 1단계: 데이터 전처리 및 피처 엔지니어링 (Data Preprocessing & Feature Engineering)

모델이 데이터를 잘 학습할 수 있도록 "깨끗하게" 만들어주는 과정입니다.

1. **결측치 처리 (Handling Missing Values)**
    
    - 제공해주신 통계 요약(describe())을 보면 count가 89개로 동일하여 현재 데이터셋에는 결측치가 없는 것으로 보입니다. 만약 다른 데이터에서 결측치가 발견된다면, 해당 행을 제거하거나, 평균/중앙값 등으로 대체하는 작업이 필요합니다.
        
2. **이상치 처리 (Handling Outliers)**
    
    - market_cap, trading_value, time_diff_sec 등의 박스 플롯에서 동그라미로 표시된 이상치(outlier)들이 보입니다.
        
    - 이러한 이상치들은 모델 성능에 악영향을 줄 수 있습니다. 제거하거나, 로그 변환(Log Transformation)을 통해 데이터 분포를 정규분포에 가깝게 만들거나, 상한/하한선을 정해 값을 제한(Winsorizing)하는 방법을 고려해볼 수 있습니다.
        
3. **피처 스케일링 (Feature Scaling)**
    
    - market_cap (시가총액)처럼 값이 매우 큰 변수와 pos처럼 0과 1 사이의 값을 갖는 변수가 함께 있습니다. 이렇게 변수 간의 단위(scale) 차이가 크면 모델이 특정 변수에만 과도하게 영향을 받을 수 있습니다.
        
    - **StandardScaler**(표준화)나 **MinMaxScaler**(정규화)를 사용하여 모든 변수들의 스케일을 비슷하게 맞춰주는 것이 좋습니다.
        
4. **피처 선택 (Feature Selection)**
    
    - **다중공선성 확인**: 상관관계 히트맵을 보면 high_rate와 current_rate의 상관계수가 **0.91**로 매우 높습니다. 이렇게 상관관계가 높은 변수들을 함께 사용하면 모델의 안정성을 해칠 수 있습니다 (다중공선성 문제). 둘 중 하나만 선택하여 사용하는 것을 강력히 추천합니다.
        
    - **범주형 데이터 처리**: media 관련 변수들은 이미 원-핫 인코딩(one-hot encoding)이 되어 있는 것으로 보입니다. 이는 모델링을 위한 올바른 처리 방법입니다.
        

---

### 2단계: 모델링 (Modeling)

이제 준비된 데이터로 예측 모델을 만드는 단계입니다.

1. **데이터 분리 (Train/Test Split)**
    
    - 전체 데이터를 모델 학습에 사용할 **훈련 데이터(Train Data)**와 모델 성능을 평가할 **테스트 데이터(Test Data)**로 분리해야 합니다. 보통 7:3 또는 8:2 비율로 분리합니다.
        
    - WL 변수의 0과 1의 비율을 유지하면서 데이터를 나누는 stratify 옵션을 사용하는 것이 좋습니다.
        
2. **베이스라인 모델 선택 (Baseline Model Selection)**
    
    - 가장 기본적이면서 해석이 용이한 모델을 먼저 만들어보는 것이 좋습니다. WL이 0(패)과 1(승) 두 가지 값을 갖는 이진 분류(Binary Classification) 문제이므로, **로지스틱 회귀(Logistic Regression)** 모델로 시작하는 것을 추천합니다.
        
3. **다양한 모델 시도 (Trying Various Models)**
    
    - 베이스라인 모델의 성능을 기준으로, 더 복잡하고 성능이 좋을 가능성이 있는 다른 모델들도 시도해 봅니다.
        
    - **결정 트리 기반 모델**: Random Forest, XGBoost, LightGBM 등은 일반적으로 분류 문제에서 높은 성능을 보입니다.
        
    - **서포트 벡터 머신 (SVM)**: 분류 문제에서 널리 사용되는 또 다른 강력한 모델입니다.
        

---

### 3단계: 모델 평가 (Model Evaluation)

만든 모델이 얼마나 예측을 잘하는지 객관적인 지표로 평가하는 단계입니다.

1. **평가 지표 선택 (Choosing Evaluation Metrics)**
    
    - 단순히 **정확도(Accuracy)**만 보는 것은 위험할 수 있습니다. (예: 100개 중 90개가 '패'인 데이터에서 모델이 전부 '패'로 예측해도 정확도는 90%가 나옴)
        
    - 다음과 같은 다양한 지표를 함께 확인해야 합니다:
        
        - **오차 행렬 (Confusion Matrix)**: 모델의 예측이 실제 값과 얼마나 일치하는지 보여주는 표
            
        - **정밀도 (Precision)**: 모델이 '승'으로 예측한 것 중 실제 '승'의 비율
            
        - **재현율 (Recall)**: 실제 '승'인 것 중 모델이 '승'으로 예측한 비율
            
        - **F1 점수 (F1-Score)**: 정밀도와 재현율의 조화 평균
            
        - **ROC 곡선 및 AUC 점수**: 클래스를 얼마나 잘 구별해내는지 나타내는 지표
            

---

### 4단계: 모델 최적화 및 해석 (Model Optimization & Interpretation)

가장 성능이 좋은 모델을 더욱 개선하고, 모델이 왜 그런 예측을 했는지 이해하는 단계입니다.

1. **하이퍼파라미터 튜닝 (Hyperparameter Tuning)**
    
    - 모델에는 성능에 영향을 미치는 여러 설정값(하이퍼파라미터)이 있습니다. **GridSearchCV**나 **RandomizedSearchCV** 같은 기법을 사용하여 최적의 하이퍼파라미터 조합을 찾습니다.
        
2. **교차 검증 (Cross-Validation)**
    
    - 데이터를 여러 번 나누어 훈련과 평가를 반복함으로써, 모델이 특정 데이터 분할에만 의존하지 않고 일반적인 성능을 갖도록 검증하는 방법입니다.
        
3. **피처 중요도 확인 (Feature Importance)**
    
    - Random Forest나 XGBoost 같은 모델은 어떤 변수(feature)가 WL 예측에 더 큰 영향을 미쳤는지 알려주는 **피처 중요도**를 제공합니다.
        
    - 이를 통해 market_cap이 중요한지, media 정보가 중요한지 등 비즈니스적으로 유의미한 인사이트를 얻을 수 있습니다.
        

### 요약: 앞으로 해야 할 일

1. **데이터 클리닝**: market_cap 등에서 보이는 이상치 처리 및 변수 간 스케일 조정을 위한 스케일링 적용.
    
2. **피처 엔지니어링**: high_rate와 current_rate 중 하나를 선택하여 다중공선성 문제 해결.
    
3. **데이터 분리**: 훈련용과 테스트용 데이터로 분할.
    
4. **모델 훈련**: 로지스틱 회귀를 시작으로 Random Forest, XGBoost 등 다양한 모델 훈련.
    
5. **모델 평가**: 정확도, 정밀도, 재현율, AUC 등 다양한 지표로 모델 성능 비교.
    
6. **모델 개선**: 가장 좋은 성능을 보인 모델을 대상으로 하이퍼파라미터 튜닝 진행.
    
7. **결과 해석**: 최종 모델의 피처 중요도를 확인하여 어떤 변수가 승/패 예측에 중요한지 파악.