결론부터 말씀드리면, **가장 먼저 해야 할 일은 '탐색적 데이터 분석(Exploratory Data Analysis, EDA)'입니다.**

모델링(확률 예측)에 들어가기 전에 데이터 자체를 깊이 있게 이해하는 과정이 반드시 필요합니다. EDA를 통해 "어느 변수가 유의미한가?", "변수 간에 어떤 관계가 있는가?", "선형인가, 비선형인가?"와 같은 질문에 대한 단서를 얻을 수 있습니다.

아래에 EDA부터 모델링까지의 체계적인 단계를 제시해 드리겠습니다.

### **1단계: 데이터 전처리 (Preprocessing)**

본격적인 분석에 앞서 모델이 이해할 수 있는 형태로 데이터를 정리해야 합니다.

1. **time_diff 변환**: 현재 time_diff는 Timedelta 객체입니다. 모델에 사용하려면 숫자로 바꿔야 합니다. 총 초(second)로 변환하는 것이 일반적입니다.
    
    codePython
    
    ```
    # time_diff를 총 초(float)로 변환
    df['time_diff_sec'] = df['time_diff'].dt.total_seconds()
    ```
    
2. **media 변환 (범주형 변수 처리)**: media는 텍스트 데이터이므로 숫자로 변환해야 합니다. 각 미디어 이름이 독립적이라고 보고 **원-핫 인코딩(One-Hot Encoding)**을 사용하는 것이 좋습니다.
    
    codePython
    
    ```
    # 원-핫 인코딩 실행
    df_encoded = pd.get_dummies(df, columns=['media'], drop_first=True)
    ```
    
3. **종속 변수(result) 변환**: '승'/'패' 문자열을 0과 1로 변환합니다. (예: 승=1, 패=0)
    
    codePython
    
    ```
    df['result_numeric'] = df['result'].apply(lambda x: 1 if x == '승' else 0)
    ```
    

### **2단계: 탐색적 데이터 분석 (EDA)**

데이터의 특성과 패턴을 파악하여 불확실성을 해소하는 단계입니다.

#### **A. 기술 통계 및 분포 확인**

- **숫자형 변수**: df.describe()를 통해 각 변수의 평균, 표준편차, 사분위수 등을 확인합니다. 이를 통해 값의 스케일 차이가 얼마나 큰지, 이상치(outlier)가 있는지 등을 파악할 수 있습니다.
    
- **범주형 변수**: df['result'].value_counts()를 통해 '승'과 '패'의 비율을 확인합니다. 만약 데이터가 심하게 불균형하다면(예: 승리가 90%, 패배가 10%) 모델링 시 추가적인 처리가 필요합니다.
    

#### **B. 시각화를 통한 변수 간 관계 파악**

이 부분이 가장 중요합니다. 독립변수와 종속변수(result) 간의 관계를 눈으로 직접 확인해야 합니다.

1. **독립변수 vs. 종속변수 (승/패) 관계 분석**
    
    - **숫자형 변수 (pos, trading_value 등)**: **박스 플롯(Box Plot)**이나 **바이올린 플롯(Violin Plot)**을 그려 '승'일 때와 '패'일 때의 분포 차이를 확인합니다. 두 그룹 간 분포에 명확한 차이가 보인다면 중요한 변수일 가능성이 높습니다.
        
        codePython
        
        ```
        import seaborn as sns
        import matplotlib.pyplot as plt
        
        # 예시: 'pos' 변수가 승/패에 따라 분포 차이가 있는지 확인
        sns.boxplot(x='result', y='pos', data=df)
        plt.show()
        ```
        
    - **범주형 변수 (media)**: **카운트 플롯(Count Plot)**이나 **교차표(Crosstab)**를 이용해 특정 언론사가 '승' 또는 '패'에 더 많이 연관되어 있는지 확인합니다.
        
2. **독립변수 간의 관계 분석**
    
    - **상관관계 히트맵(Correlation Heatmap)**: 숫자형 독립변수들 간의 상관관계를 한눈에 파악합니다. 상관관계가 매우 높은 변수들(예: high_rate와 current_rate)이 있다면 **다중공선성(multicollinearity)** 문제가 발생할 수 있으며, 모델에 따라 변수 선택이 필요할 수 있습니다.
        
        codePython
        
        ```
        # 상관관계 행렬 계산 (숫자형 데이터만 선택)
        corr_matrix = df_numeric.corr()
        
        # 히트맵으로 시각화
        plt.figure(figsize=(10, 8))
        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')
        plt.show()
        ```
        



### 2.5단계: 스케일링





### **3단계: 모델링 전략 수립**

EDA를 통해 얻은 인사이트를 바탕으로 모델링 전략을 세웁니다.

1. **간단한 모델로 시작 (Baseline Model)**: 처음부터 복잡한 모델을 사용하는 것보다 해석이 용이한 **로지스틱 회귀 (Logistic Regression)** 모델을 먼저 사용해 보세요.
    
    - **장점**: 각 독립변수가 '승리 확률'에 얼마나 영향을 미치는지(계수, coefficient)를 직관적으로 파악할 수 있습니다. 이를 통해 변수의 영향력(긍정적/부정적)과 중요도를 초기에 가늠할 수 있습니다. 선형 관계를 가정하지만, 훌륭한 출발점입니다.
        
2. **비선형 및 교호작용을 고려한 모델 사용**:
    
    - EDA 결과 변수 간 관계가 비선형적이거나 복잡한 교호작용이 의심된다면, **결정 트리(Decision Tree)** 기반의 앙상블 모델인 **랜덤 포레스트(Random Forest)**나 **XGBoost**, **LightGBM** 같은 모델을 사용하는 것이 매우 효과적입니다.
        
    - **장점**:
        
        - 자동으로 변수 간의 비선형 관계와 교호작용을 학습합니다.
            
        - **변수 중요도(Feature Importance)**를 제공하여 어떤 변수가 예측에 가장 큰 영향을 미치는지 알려줍니다. 이는 "어느 변수가 실제로 종속변수에 영향을 미치는가"라는 질문에 대한 직접적인 답이 됩니다.
            

### **결론 및 다음 행동 계획**

**지금 당장 해야 할 일은 다음과 같습니다.**

1. **데이터 전처리**: 위에서 설명한 대로 time_diff, media, result 열을 숫자 형태로 변환하세요.
    
2. **시각화 중심의 EDA 수행**:
    
    - 각 독립변수에 대해 result('승'/'패') 그룹별로 박스 플롯을 그려보세요. 분포 차이가 뚜렷하게 나타나는 변수가 핵심 변수 후보입니다.
        
    - 숫자형 변수들 간의 상관관계 히트맵을 그려서 변수들 사이의 관계를 파악하세요.
        
3. **베이스라인 모델 수립**: 전처리된 데이터로 **로지스틱 회귀** 모델을 학습시켜 각 변수의 영향력을 대략적으로 파악하세요.
    
4. **고급 모델 적용**: **랜덤 포레스트** 또는 **XGBoost**를 사용하여 변수 중요도를 확인하고, 더 높은 예측 성능을 목표로 하세요. 이 모델의 변수 중요도 결과가 현재로서는 가장 신뢰할 만한 "영향력 있는 변수" 목록이 될 것입니다.
    

**향후 확장 가능성**에 대해서도 이 접근 방식은 유효합니다. title을 자연어 처리하여 얻은 숫자 벡터(예: TF-IDF)를 독립변수로 추가하거나, 종속변수를 max_10m(연속형)으로 바꿔 회귀 문제로 전환하더라도 EDA를 통해 데이터의 특성을 이해하는 과정은 동일하게 중요합니다.****